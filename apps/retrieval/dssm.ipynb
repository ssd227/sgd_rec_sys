{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŒå¡”æ¨¡å‹\n",
    "1) Pointwise è®­ç»ƒ\n",
    "2) Pairwise è®­ç»ƒ\n",
    "3) Listwise è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_rec_sys\n"
     ]
    }
   ],
   "source": [
    "%cd /playground/sgd_deep_learning/sgd_rec_sys/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sgd_rec_sys.data import FakeDssmDataFactory, DssmDataset\n",
    "from sgd_rec_sys.retrieval import DSSM, DefaultItemTower, DefaultUserTower, \\\n",
    "TripletHingeLoss, TripletLogisticLoss, CrossEntropyLoss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Pointwiseè®­ç»ƒ\n",
    "æŠŠå¬å›çœ‹åšâ¼†å…ƒåˆ†ç±»ä»»åŠ¡ã€‚\n",
    "* å¯¹äºæ­£æ ·æœ¬ï¼Œâ¿åŠ±cos ğš, ğ› æ¥è¿‘+1ã€‚\n",
    "* å¯¹äºè´Ÿæ ·æœ¬ï¼Œâ¿åŠ±cos ğš, ğ› æ¥è¿‘âˆ’1ã€‚\n",
    "* æ§åˆ¶æ­£è´Ÿæ ·æœ¬æ•°é‡ä¸º1: 2æˆ–è€…1: 3ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç°æœ‰æ¡†æ¶ä¸‹ï¼Œfakeæ•°æ®éœ€è¦é‡æ–°æ„é€ ï¼Œ æ¯”è¾ƒç®€å•ï¼Œæš‚æ—¶pass\n",
    "# ä½¿ç”¨äº¤å‰ç†µé¢„æµ‹æ­£è´Ÿæ ·æœ¬(1ï¼Œ0)ã€‚ \n",
    "\n",
    "## æ•°æ®å‡†å¤‡\n",
    "## å‚æ•°è®¾ç½®"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Pairwiseè®­ç»ƒ\n",
    "\n",
    "```\n",
    "    é’ˆå¯¹pairwiseè‡ªå®šä¹‰äº†TripletHingeLoss\n",
    "        input: \n",
    "            cos(a,b+), cos(a,b-)\n",
    "            ä¸¤ä¸ªcoså€¼å·²åœ¨dssmé‡Œè®¡ç®—å¥½äº†\n",
    "\n",
    "        è¶…å‚æ•°ï¼š\n",
    "            triplet_hinge_loss_mï¼Œéœ€è¦è¿›è¡Œç½‘æ ¼æœç´¢\n",
    "            \n",
    "            é»˜è®¤è®¾ç½®ä¸º1ï¼Œç”±äºcosçš„å–å€¼åœ¨[-1,1], \n",
    "            æé™æ¡ä»¶ä¸‹æ­£æ ·æœ¬ä¸º1ï¼Œè´Ÿæ ·æœ¬ä¸º-1ï¼Œé—´éš”ä¸º2ï¼Œè¿™é‡Œå–ä¸­é—´é—´éš”1\n",
    "\n",
    "    from chatgpt:\n",
    "        åœ¨ Triplet Hinge Loss ä¸­ï¼Œå‚æ•° m æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ­£ä¾‹å’Œè´Ÿä¾‹ä¹‹é—´çš„é—´éš”ã€‚\n",
    "        é€šå¸¸æƒ…å†µä¸‹ï¼Œm çš„é€‰æ‹©ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n",
    "        \n",
    "        é€‰æ‹©åˆé€‚çš„ m å€¼é€šå¸¸éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚\n",
    "        ä¸€èˆ¬æ¥è¯´ï¼Œè¾ƒå°çš„ m å€¼ä¼šä½¿å¾—æ¨¡å‹æ›´åŠ å…³æ³¨äºéš¾ä»¥åŒºåˆ†çš„æ ·æœ¬ï¼Œä»è€Œæ›´å¥½åœ°æ¨åŠ¨æ¨¡å‹å‘ç€æ›´å¥½çš„æ–¹å‘è®­ç»ƒã€‚\n",
    "        ä½†æ˜¯ï¼Œå¦‚æœé€‰æ‹©è¿‡å°çš„ m å€¼ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆæˆ–è®­ç»ƒä¸ç¨³å®šã€‚\n",
    "\n",
    "        ç›¸åï¼Œè¾ƒå¤§çš„ m å€¼ä¼šä½¿å¾—æ¨¡å‹æ›´åŠ å…³æ³¨äºæ˜“äºåŒºåˆ†çš„æ ·æœ¬ï¼Œ\n",
    "        ä»è€Œå¯èƒ½å¯¼è‡´æ¨¡å‹è¿‡åº¦ç®€åŒ–æˆ–è€…å¿½è§†éš¾ä»¥åŒºåˆ†çš„æ ·æœ¬ã€‚\n",
    "        ä½†æ˜¯ï¼Œé€‰æ‹©è¿‡å¤§çš„ m å€¼å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹éš¾ä»¥æ”¶æ•›æˆ–è€…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚\n",
    "\n",
    "        å› æ­¤ï¼Œé€‰æ‹©åˆé€‚çš„ m å€¼éœ€è¦åœ¨æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œå®éªŒå’Œè°ƒæ•´ã€‚\n",
    "        æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨äº¤å‰éªŒè¯æˆ–è€…ç½‘æ ¼æœç´¢ç­‰æ–¹æ³•æ¥é€‰æ‹©æœ€ä½³çš„ m å€¼ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "        é€šå¸¸æƒ…å†µä¸‹ï¼Œm çš„å–å€¼èŒƒå›´å¯ä»¥ä»ä¸€ä¸ªå°çš„æ­£æ•°å¼€å§‹å°è¯•ï¼Œç„¶åæ ¹æ®å®é™…æ•ˆæœé€æ­¥è°ƒæ•´ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user feature embedding success, shape: (1000, 80)\n",
      "item feature embedding success, shape: (1000, 2, 90)\n"
     ]
    }
   ],
   "source": [
    "## æ•°æ®å‡†å¤‡ ##\n",
    "\n",
    "# input\n",
    "n_samples = 1000 # æ€»æ ·æœ¬æ•°\n",
    "user_fea_dim = 80\n",
    "item_fea_dim = 90\n",
    "item_fea_num = 2 # ï¼ˆæ­£æ ·æœ¬1: è´Ÿæ ·æœ¬1ï¼‰\n",
    "\n",
    "## ç”Ÿæˆä¼ªCTRæ•°æ®\n",
    "dump_file = './data/fake/tmp_dssm.pkl'\n",
    "fake_data_factory = FakeDssmDataFactory(n_samples,\n",
    "                                        user_fea_dim,\n",
    "                                        item_fea_dim,\n",
    "                                        item_fea_num,\n",
    "                                        dtype=np.float32)\n",
    "fake_data_factory.presist(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "DSSM(\n",
      "  (item_tower): DefaultItemTower(\n",
      "    (nns): Sequential(\n",
      "      (0): Linear(in_features=90, out_features=180, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=180, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (user_tower): DefaultUserTower(\n",
      "    (nns): Sequential(\n",
      "      (0): Linear(in_features=80, out_features=160, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=160, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## å‚æ•°è®¾ç½® ##\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "train_batch_size = 64\n",
    "epochs = 5\n",
    "triplet_hinge_loss_m = 1 # è¶…å‚æ•°éœ€è¦ç½‘æ ¼æœç´¢\n",
    "\n",
    "with open(dump_file,'rb') as f:\n",
    "    fake_data = pickle.load(f)\n",
    "train_ds = DssmDataset(data_info=fake_data, device=device)\n",
    "train_dl = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# ç½‘ç»œç»“æ„\n",
    "out_dim = 128 # åœ¨128ç»´åº¦ä¸Šåšå†…ç§¯æˆ–è€…cosinç›¸ä¼¼åº¦\n",
    "user_hidden_dims = [int(user_fea_dim*2), 1024, 256, out_dim]\n",
    "item_hidden_dims = [int(item_fea_dim*2), 1024, 256, out_dim]\n",
    "\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "user_tower = DefaultUserTower(in_dim=user_fea_dim,\n",
    "                              hidden_dims = user_hidden_dims,\n",
    "                              activation_fun=nn.ReLU())\n",
    "                             \n",
    "item_tower = DefaultItemTower(in_dim=item_fea_dim, \n",
    "                              hidden_dims= item_hidden_dims, \n",
    "                              activation_fun=nn.ReLU())\n",
    "\n",
    "model = DSSM(item_tower=item_tower,\n",
    "             user_tower= user_tower,).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = TripletHingeLoss(m=triplet_hinge_loss_m)  # Pairwise loss\n",
    "# criterion = TripletLogisticLoss(sigma=1)  # Pairwise loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # SGD ä¼˜åŒ–å™¨\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-1, weight_decay=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0012\n",
      "Epoch [2/5], Loss: 0.9996\n",
      "Epoch [3/5], Loss: 0.9999\n",
      "Epoch [4/5], Loss: 1.0002\n",
      "Epoch [5/5], Loss: 1.0001\n"
     ]
    }
   ],
   "source": [
    "## è®­ç»ƒ ##\n",
    "def train(dataloader, model, epochs=1,):\n",
    "    for epoch in range(epochs):\n",
    "        for x in dataloader:\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs[:,0], outputs[:,1])\n",
    "        \n",
    "        # åå‘ä¼ æ’­å’Œä¼˜åŒ–\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "train(train_dl, model, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Listwiseè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user feature embedding success, shape: (1000, 80)\n",
      "item feature embedding success, shape: (1000, 10, 90)\n"
     ]
    }
   ],
   "source": [
    "## æ•°æ®å‡†å¤‡ ##\n",
    "\n",
    "# input\n",
    "n_samples = 1000 # æ€»æ ·æœ¬æ•°\n",
    "user_fea_dim = 80\n",
    "item_fea_dim = 90\n",
    "item_fea_num = 10 # ï¼ˆæ­£æ ·æœ¬1: è´Ÿæ ·æœ¬9ï¼‰\n",
    "\n",
    "## ç”Ÿæˆä¼ªCTRæ•°æ®\n",
    "dump_file = './data/fake/tmp_dssm.pkl'\n",
    "fake_data_factory = FakeDssmDataFactory(n_samples,\n",
    "                                        user_fea_dim,\n",
    "                                        item_fea_dim,\n",
    "                                        item_fea_num,\n",
    "                                        dtype=np.float32)\n",
    "fake_data_factory.presist(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "DSSM(\n",
      "  (item_tower): DefaultItemTower(\n",
      "    (nns): Sequential(\n",
      "      (0): Linear(in_features=90, out_features=180, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=180, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (user_tower): DefaultUserTower(\n",
      "    (nns): Sequential(\n",
      "      (0): Linear(in_features=80, out_features=160, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=160, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## å‚æ•°è®¾ç½® ##\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "train_batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "with open(dump_file,'rb') as f:\n",
    "    fake_data = pickle.load(f)\n",
    "train_ds = DssmDataset(data_info=fake_data, device=device)\n",
    "train_dl = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# ç½‘ç»œç»“æ„\n",
    "out_dim = 128 # åœ¨128ç»´åº¦ä¸Šåšå†…ç§¯æˆ–è€…cosinç›¸ä¼¼åº¦\n",
    "user_hidden_dims = [int(user_fea_dim*2), 1024, 256, out_dim]\n",
    "item_hidden_dims = [int(item_fea_dim*2), 1024, 256, out_dim]\n",
    "\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "user_tower = DefaultUserTower(in_dim=user_fea_dim,\n",
    "                              hidden_dims = user_hidden_dims,\n",
    "                              activation_fun=nn.ReLU())\n",
    "                             \n",
    "item_tower = DefaultItemTower(in_dim=item_fea_dim, \n",
    "                              hidden_dims= item_hidden_dims, \n",
    "                              activation_fun=nn.ReLU())\n",
    "\n",
    "model = DSSM(item_tower=item_tower,\n",
    "             user_tower= user_tower,).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # SGD ä¼˜åŒ–å™¨\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-1, weight_decay=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.3040\n",
      "Epoch [2/5], Loss: 2.3029\n",
      "Epoch [3/5], Loss: 2.3036\n",
      "Epoch [4/5], Loss: 2.3039\n",
      "Epoch [5/5], Loss: 2.3008\n"
     ]
    }
   ],
   "source": [
    "## è®­ç»ƒ ##\n",
    "def train(dataloader, model, epochs=1,):\n",
    "    for epoch in range(epochs):\n",
    "        for x in dataloader:\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs)\n",
    "        \n",
    "        # åå‘ä¼ æ’­å’Œä¼˜åŒ–\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "train(train_dl, model, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
